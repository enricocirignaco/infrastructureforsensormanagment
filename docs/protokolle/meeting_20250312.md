# Meeting 12.03.2025
## Teilnehmer
- Linus Degen
- Enrico Cirignaco
- Nikita Aigner
- Pascal Mainini
- Christine Moos

## Besprechung / Input Christine

- R wird verwendet für die Datenauswertung, GIS-Systeme bei räumlichen Daten
- Datenbankzugriff bis jetzt selten/nie direkt über Christine, Option besteht jedoch
- Daten auch besonders längerfristig interessant in Internet of Soils
- Christine sieht Vernetzung mit Daten von beispielsweise LINDAS (Meteoswiss, Waldbrandgefahr, ...) als sehr interessant

### Konkrete Fragen
**Frage:** Wie oft passiert es, dass verschiedenste Daten (Tabellen, CSV, Bilder, etc.) zusammengeführt werden müssen? <br>
**Antwort:** Passiert oft, typischer Anwendungsfall. Oft auch in Kombination mit einem GIS-System.

**Frage:** Bevorzugtes Format beim Import in R? <br>
**Antwort:** CSV oder Text-File.

**Rückfrage:** Könnte man in R auch eine Datenbank einbinden? <br>
**Antwort:** Sollte solche Datenbanken geben. Aber auch SparQL-Einbindung mit CSV-Generierung direkt möglich.

**Frage:** Ist es erwünscht, beim Download des CSVs diese direkt schon filtern zu können? <br>
**Antwort:** Wahrscheinlich besonders dann erwünscht, wenn Datenmengen gross werden. Momentan sind die Datenreihen aber überschaubar.

**Frage:** Welche Daten werden bei der Auswertung von IoS konkret verwendet? <br>
**Antwort:** Entwicklung der Zeitreihen, in Abhängigkeit von Topografie (Höhemodell), Daten zur Vegetation (Waldbestand) in Bietsch Daten von der (WSL), klimatische Daten

**Frage:** Darstellung der Zeitserien im Web-UI? <br>
**Antwort:** Einen öffentlichen Zugang auf die Daten wäre interessant, damit auch Forstbetriebe oder so darauf zugreifen könnten. 
Immernoch explorative Phase, sind die Daten so sinnvoll?
In einem späteren Schritt dann vielleicht sinnvoll. Jedoch out of Scope, würde den Rahmen sprengen innerhalb der Bachelorarbeit.
Fokus auf effektives Verwalten und Ausbringen von Sensorknoten. Vielleicht später sogar Integration in LINDAS?

**Frage:** Sollte der SparQL-Endpoint zur Verfügung stehen? <br>
**Antwort:** Ja definitiv. Natürlich nicht ins Internet, aber die Idee ist es ja komplexe Queries auf den Triplestore abzusetzen.

Thema Export der Daten: Einfach ein beispielhafter Export bereitstellen, welcher ausgeführt werden kann.
Integration mit R im Hinterkopf behalten. Jedoch sollte alles im RDF-Bereich mit R möglich sein.

Erstmals den Graphen bauen (Sensordaten, Metadaten etc.). Der Export kann dann auch über ein Python-Script funktionieren, welches über SparQL in CSV konvertiert.

## Nachbesprechung Nikita/Pascal

Thema Logging: Wenn ein Benutzer eine Aktion/Mutation durchführt, soll ein Logbook 
History pro Sensornode/Projekt. Dann gibt es Aktionen wie z.B. "Projekt erstellt", "Sensorknoten-Namen angepasst"

Zu wenig in Requirements abgebildet:
- Datenerfassung, Linked-Data Ansatz.
- Etwas zu wenig abgebildet, wie Daten wirklich ab- und angelegt werden sollen
- Hohe Priorität: Projektdaten in Linked-Data
- Nikita hat definitiv Interesse an der Datenstruktur im Linked-Data Format und möchte das auch so weiterverwenden

Möglichst früh beginnen Daten zu modellieren. Kann auch einfach über Turtle sein. Damit man möglichst schnell von einem konkreten Modell.
Separates Git-Repo, um Daten zu modellieren und austauschen zu können (z.B. Turtle-File).
Konkrete Projekte, Benutzer etc. erfassen, danach kann man von Ontologien und Schemas beginenn zu sprechen.
Intern brauchen wir formelle Ontologien nicht unbedingt, Daten-zentrisch arbeiten.

Ziel: End-to-End lauffähiges System. Sensor erfassen, Firmware builden und flashen, Datenmodell ersichtbar. Fokus auf Einsetzbarkeit, welches Nikita auch konkret verwenden kann und dass alle Aspekte abgebildet sind.